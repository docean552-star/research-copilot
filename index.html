<!DOCTYPE html>
<html lang="ru">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Научная статья с нуля: гайд по работе с AI-экосистемой</title>
<link rel="stylesheet" href="guide.css">
</head>
<body>
<button class="theme-toggle" onclick="toggleTheme()">Светлая тема</button>
<nav class="scroll-nav" id="scrollNav"></nav>
<div class="container">

<h1>Научная статья с нуля: гайд по работе с AI-экосистемой</h1>
<p>Для тех, кто никогда не работал с AI, но хочет написать научную статью с их помощью. Всё что нужно &mdash; этот файл и приложение Claude.</p>

<!-- ═══════════════════ TOC ═══════════════════ -->

<div class="toc">
<h2 style="margin-top:0">Оглавление</h2>
<a href="#bootstrap">Быстрый старт: настройка проекта</a>
<a href="#tools">Инструменты: что ставить и зачем</a>
<a href="#phase0">Фаза 0: Формулировка исследовательского вопроса</a>
<a href="#phase1">Фаза 1: Разведка (Google Deep Research)</a>
<a href="#phase2">Фаза 2: Глубокий поиск литературы</a>
<a href="#phase3">Фаза 3: Сбор источников</a>
<a href="#phase4">Фаза 4: Построение базы знаний (NotebookLM)</a>
<a href="#phase5">Фаза 5: Синтез (Claude + NotebookLM)</a>
<a href="#phase6">Фаза 6: Написание (Claude)</a>
<a href="#phase7">Фаза 7: Критический разбор (Claude как рецензент)</a>
<a href="#phase8">Фаза 8: Верификация (NotebookLM + scite.ai)</a>
<a href="#phase9">Фаза 9: Финализация</a>
<a href="#files">Файловая структура проекта</a>
<a href="#principles">Принципы (перечитывай когда сомневаешься)</a>
<a href="#checklist">Финальный чеклист</a>
<a href="#glossary">Глоссарий: основные термины</a>
</div>

<!-- ═══════════════════ BOOTSTRAP ═══════════════════ -->

<details class="section" id="bootstrap">
<summary>Быстрый старт: настройка проекта</summary>
<div class="phase">

<h3>Шаг 1: Установи приложение Claude</h3>
<p>Скачай Claude с <a href="https://claude.ai/download">claude.ai/download</a>. Установи как обычную программу. Открой.</p>

<h3>Шаг 2: Скачай шаблоны</h3>
<p>Нажми кнопку &mdash; в папку Загрузки скачается файл <code>templates.md</code> с инструкциями для агента.</p>
<p><button class="download-templates" onclick="downloadTemplates()">Скачать templates.md</button></p>

<h3>Шаг 3: Создай проект</h3>
<p>Скопируй и отправь этот промт в приложение:</p>
<pre><code>Прочитай файл templates.md из моей папки Загрузки и создай
рабочий проект для научной статьи.

Путь к Загрузкам (подставь своё имя пользователя):
- Windows: C:/Users/ИМЯ/Downloads/templates.md
- Mac: ~/Downloads/templates.md

Если в пути кириллица и файл не читается — скажи,
я перемещу файл в другое место.

Создай проект с английским именем (без кириллицы в пути).</code></pre>

<div class="warn"><b>Кириллица в пути:</b> если имя пользователя на русском (например <code>C:/Users/Иван/</code>), агент может не прочитать файл из Загрузок. В таком случае перемести <code>templates.md</code> в папку без русских букв, например <code>C:/temp/</code>, и скажи агенту новый путь.</div>

<h3>Шаг 4: Начинай работу</h3>
<p>Агент создаст структуру проекта и будет готов к Фазе 0. Открой нужную фазу в этом гайде, скопируй промт из блока внизу фазы и отправь агенту.</p>

<p><b>Повторное использование:</b> этот гайд &mdash; не одноразовый. Для каждой новой статьи попроси агента создать новый проект. Твой опыт, шаблоны и настройки сохраняются между проектами.</p>

</div>
</details>

<!-- ═══════════════════ TOOLS ═══════════════════ -->

<details class="section" id="tools">
<summary>Инструменты: что ставить и зачем</summary>
<div class="phase">

<p>Перед началом работы тебе нужно 6 инструментов. Каждый решает свою задачу &mdash; ни один не заменяет другой.</p>

<h3>1. Claude (приложение)</h3>
<p><span class="tool-badge">Синтез</span> <span class="tool-badge">Текст</span> <span class="tool-badge">Критика</span> <span class="tool-badge">Файлы</span></p>
<p>AI-ассистент от Anthropic. Лучший для рассуждений, структурирования мыслей, написания текста. Работает с файлами на твоём компьютере &mdash; создаёт, редактирует, организует.</p>
<p><b>Установка:</b> скачай приложение с <a href="https://claude.ai/download">claude.ai/download</a>. Обычная программа &mdash; скачал, установил, открыл. Для серьёзной работы нужен Pro ($20/мес).</p>
<div class="warn"><b>Ключевое ограничение:</b> Claude выдумывает источники. Он напишет "Smith et al. (2024) demonstrated that..." &mdash; и эта статья не существует. НИКОГДА не бери ссылки из Claude без проверки.</div>

<h3>2. NotebookLM (notebooklm.google.com)</h3>
<p><span class="tool-badge">База знаний</span> <span class="tool-badge">Верификация</span> <span class="tool-badge">Цитаты</span></p>
<p>AI от Google (Gemini), который работает ТОЛЬКО с твоими загруженными документами. Загружаешь 50 PDF &mdash; спрашиваешь &mdash; отвечает С ЦИТАТОЙ из конкретного документа и страницы.</p>
<p><b>Доступ:</b> бесплатно. Google-аккаунт. notebooklm.google.com.</p>
<div class="tip"><b>Почему центральный инструмент:</b> это ЕДИНСТВЕННЫЙ AI в системе, который не выдумывает. Он отвечает только на основе загруженных документов. Если в твоих PDF нет ответа &mdash; он скажет "не нашёл". Claude никогда так не сделает.</div>
<p><b>Audio Overview:</b> NotebookLM генерирует аудио-подкаст по загруженным документам. Два голоса обсуждают содержимое твоих статей. Помогает охватить общую картину из 20 статей за 15 минут.</p>

<h3>3. Google Deep Research (gemini.google.com)</h3>
<p><span class="tool-badge">Разведка</span> <span class="tool-badge">Обзор поля</span></p>
<p>AI-агент внутри Gemini, который сам ищет в интернете, читает десятки страниц и возвращает структурированный отчёт.</p>
<p><b>Доступ:</b> Gemini Advanced ($20/мес) или бесплатная версия (может быть ограничен).</p>
<div class="warn"><b>Ограничение:</b> ищет только в открытом вебе. Статьи за пейволлом не прочитает. Но найдёт названия, абстракты и контекст.</div>

<h3>4. Zotero (zotero.org)</h3>
<p><span class="tool-badge">Библиография</span> <span class="tool-badge">PDF</span> <span class="tool-badge">Организация</span></p>
<p>Бесплатный менеджер библиографии. Не AI &mdash; просто очень полезная программа.</p>
<p><b>Установка:</b></p>
<ol>
<li>Скачай десктопное приложение с zotero.org</li>
<li>Установи Zotero Connector &mdash; расширение для браузера</li>
<li>Зарегистрируйся для синхронизации (бесплатно, 300 МБ)</li>
</ol>
<p><b>Как работает:</b> открываешь статью в Google Scholar &rarr; нажимаешь иконку Zotero в браузере &rarr; статья сохраняется с метаданными. Если PDF доступен &mdash; скачивается автоматически.</p>

<h3>5. Unpaywall (unpaywall.org)</h3>
<p><span class="tool-badge">Open Access</span></p>
<p>Бесплатное расширение для браузера. На странице статьи за пейволлом показывает зелёный замочек, если есть open access версия. 30-40% статей имеют такую версию.</p>
<p><b>Установка:</b> Chrome Web Store &rarr; "Unpaywall" &rarr; установить. Работает автоматически.</p>

<h3>6. Connected Papers (connectedpapers.com)</h3>
<p><span class="tool-badge">Поиск</span> <span class="tool-badge">Визуальный граф</span></p>
<p>Вводишь одну статью &mdash; получаешь граф из 40+ связанных работ. Находишь статьи, которые не знал что искать.</p>
<p><b>Доступ:</b> бесплатно 5 графов в месяц.</p>

<h3>7. scite.ai</h3>
<p><span class="tool-badge">Верификация</span> <span class="tool-badge">Цитирования</span></p>
<p>Показывает КАК статью цитируют: supporting (подтверждают), contrasting (опровергают), mentioning (просто упоминают). Если статью цитируют 50 раз, но 30 &mdash; contrasting, это red flag.</p>
<p><b>Доступ:</b> бесплатный с ограничениями. $20/мес для полного (студенческая скидка есть).</p>

</div>
</details>

<!-- ═══════════════════ PHASE 0 ═══════════════════ -->

<details class="section" id="phase0">
<summary>Фаза 0: Формулировка исследовательского вопроса</summary>
<div class="phase">
<p><span class="tool-badge">Claude</span></p>

<h3>Шаг 0.1: Опиши тему своими словами</h3>
<p>Отправь агенту примерно так:</p>
<pre><code>Я пишу научную статью. Моя тема в свободной формулировке:
[опиши как понимаешь, можно коряво, главное — суть]

Помоги мне:
1. Сформулировать research question — чёткий исследовательский вопрос
2. Объяснить почему этот вопрос важен (research gap)
3. Предложить 3-5 вариантов формулировки от широкой к узкой</code></pre>

<h3>Шаг 0.2: Проверь вопрос по критериям</h3>
<div class="table-wrap"><table>
<tr><th>Критерий</th><th>Что значит</th><th>Плохой пример</th><th>Хороший пример</th></tr>
<tr><td>Конкретный</td><td>Не "про всё", а про конкретный аспект</td><td>Как AI влияет на образование?</td><td>Как LLM-чатботы влияют на критическое мышление у студентов бакалавриата?</td></tr>
<tr><td>Исследуемый</td><td>Можно ответить на основе данных</td><td>Что лучше &mdash; AI или человек?</td><td>Какие факторы определяют доверие пользователей к AI-рекомендациям в медицине?</td></tr>
<tr><td>Фальсифицируемый</td><td>Можно опровергнуть</td><td>AI полезен для общества</td><td>AI-диагностика снижает количество врачебных ошибок в рентгенологии</td></tr>
<tr><td>Новый</td><td>Не повторяет уже отвеченное</td><td>Работает ли ML для классификации?</td><td>Как отличается точность LLM zero-shot vs fine-tuned на малых датасетах (&lt;100) в медтекстах?</td></tr>
</table></div>

<p>Попроси агента проверить:</p>
<pre><code>Вот мой исследовательский вопрос: [вопрос]

Проверь по критериям:
- Конкретность: достаточно ли узко?
- Исследуемость: можно ли ответить на основе литературы?
- Фальсифицируемость: можно ли опровергнуть?
- Новизна: не отвечена ли тема уже?

Если слабый — предложи как усилить.</code></pre>

<h3>Шаг 0.3: Сгенерируй поисковые термины</h3>
<pre><code>Мой исследовательский вопрос: [вопрос]

Сгенерируй:
1. 15-20 поисковых запросов на английском для Google Scholar
2. 5-7 ключевых терминов для Semantic Scholar
3. Список синонимов и связанных понятий
4. MeSH-термины если тема медицинская</code></pre>

<h3>Шаг 0.4: Заведи search-log</h3>
<p>Создай текстовый файл <code>search-log.txt</code>:</p>
<pre><code>SEARCH LOG
==========

Исследовательский вопрос:
[финальная формулировка]

Поисковые термины:
- [термин 1]
- [термин 2]
- ...

Критерии включения:
- Язык: английский (+ русский если релевантно)
- Годы: [диапазон, обычно последние 10 лет, ядро — последние 5]
- Тип: peer-reviewed journal articles, conference papers

Критерии исключения:
- Opinion pieces без эмпирических данных
- Статьи не на английском/русском
- Тезисы конференций без полного текста

Лог поиска:
[заполняешь в Фазе 2]</code></pre>

<p><b>ТЫ решаешь</b> какой вопрос исследовать. Claude помогает сформулировать, финальное решение &mdash; твоё.</p>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 0</summary>
<div class="content">
<p>Скопируй и отправь агенту:</p>
<pre><code>Начинаем фазу 0: формулировка исследовательского вопроса.

Моя тема (своими словами): [опиши тему как понимаешь]

Помоги сформулировать чёткий research question.</code></pre>
<p><b>Что будет:</b> агент предложит варианты формулировки, проверит по критериям, сгенерирует поисковые термины и создаст search-log.txt.</p>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 1 ═══════════════════ -->

<details class="section" id="phase1">
<summary>Фаза 1: Разведка (Google Deep Research)</summary>
<div class="phase">
<p><span class="tool-badge">Google Deep Research</span></p>

<h3>Шаг 1.1: Запусти Deep Research</h3>
<p>Зайди на gemini.google.com. Выбери Gemini 2.5 Pro. Введи:</p>
<pre><code>Я пишу научную статью по теме: [твой research question]

Сделай глубокий обзор:
1. Кто ключевые исследователи (top 10 авторов)?
2. Какие основные теоретические рамки?
3. Ключевые эмпирические результаты за последние 5 лет?
4. Какие научные дебаты / нерешённые вопросы?
5. Какие методологические подходы доминируют?
6. Какие журналы публикуют по этой теме?
7. Есть ли мета-анализы или systematic reviews?

Для каждого пункта — конкретные источники (авторы, год, название).</code></pre>
<p>Deep Research уйдёт на 5-10 минут &mdash; он откроет десятки страниц, прочитает, скомпилирует. Дождись.</p>

<h3>Шаг 1.2: Оцени результат</h3>
<ol>
<li><b>Прочитай целиком</b> &mdash; это твоя карта территории</li>
<li><b>Выпиши ключевых авторов</b> &mdash; их статьи будешь искать первыми</li>
<li><b>Выпиши новые термины</b> &mdash; добавь в search-log</li>
<li><b>Отметь мета-анализы и systematic reviews</b> &mdash; если есть, это золото</li>
</ol>

<div class="warn"><b>Ограничения Deep Research:</b> ищет только в открытом вебе, может hallucinate источники, его отчёт &mdash; СТАРТОВАЯ ТОЧКА, не финальный литобзор.</div>

<h3>Шаг 1.3: Обнови search-log</h3>
<p>Добавь в search-log.txt секцию:</p>
<pre><code>ФАЗА 1: РАЗВЕДКА (Deep Research)
Дата: [дата]

Ключевые авторы:
- [Автор 1] — [почему важен]
- [Автор 2] — ...

Ключевые теории/рамки:
- [Framework 1]
- [Framework 2]

Мета-анализы:
- [Название, авторы, год]

Новые поисковые термины (добавлены):
- [термин]

Журналы по теме:
- [Journal 1]
- [Journal 2]</code></pre>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 1</summary>
<div class="content">
<p>Эта фаза выполняется в <b>Google Deep Research</b> (gemini.google.com), не в Claude. После получения отчёта скопируй результат и отправь агенту:</p>
<pre><code>Фаза 1: разведка завершена. Вот отчёт Deep Research:

[вставь отчёт]

Помоги разобрать: выдели ключевых авторов, теории,
мета-анализы. Обнови search-log.txt.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 2 ═══════════════════ -->

<details class="section" id="phase2">
<summary>Фаза 2: Глубокий поиск литературы</summary>
<div class="phase">
<p><span class="tool-badge">Google Scholar</span> <span class="tool-badge">Connected Papers</span> <span class="tool-badge">Semantic Scholar</span></p>

<h3>Шаг 2.1: Google Scholar (scholar.google.com)</h3>
<p><b>Операторы поиска:</b></p>
<div class="table-wrap"><table>
<tr><th>Оператор</th><th>Что делает</th><th>Пример</th></tr>
<tr><td><code>"exact phrase"</code></td><td>Точная фраза</td><td><code>"critical thinking" LLM</code></td></tr>
<tr><td><code>allintitle:</code></td><td>Слова только в заголовке</td><td><code>allintitle: LLM critical thinking</code></td></tr>
<tr><td><code>author:"Name"</code></td><td>Статьи конкретного автора</td><td><code>author:"Smith"</code></td></tr>
<tr><td><code>site:</code></td><td>Только с конкретного сайта</td><td><code>site:arxiv.org</code></td></tr>
</table></div>
<p>Фильтр по годам &mdash; слева на странице результатов.</p>

<p><b>Для каждого результата:</b></p>
<ol>
<li>Прочитай заголовок и абстракт</li>
<li>Релевантно? &rarr; нажми иконку Zotero в браузере &rarr; сохранится</li>
<li>Не уверен? &rarr; сохрани, разберёшься позже. Лучше лишнее чем потерять нужное</li>
</ol>

<p><b>"Cited by" и "Related articles":</b> под каждым результатом. "Cited by 142" &mdash; кто цитирует эту статью (часто самые свежие работы). "Related articles" &mdash; похожие по тексту.</p>

<h3>Шаг 2.2: Connected Papers</h3>
<ol>
<li>Зайди на connectedpapers.com</li>
<li>Вставь название или DOI ключевой статьи</li>
<li>"Build a graph"</li>
</ol>
<p>Каждый кружок &mdash; статья. Размер = цитирования, близость = степень связи, цвет = год (тёмные &mdash; старые, светлые &mdash; новые).</p>
<p><b>Два режима:</b> Prior Works (фундамент области) и Derivative Works (передовой край). Кликай, читай абстракты, сохраняй в Zotero.</p>

<h3>Шаг 2.3: Semantic Scholar (semanticscholar.org)</h3>
<p>Лучшие фильтры чем Scholar. "Highly Influential Citations" &mdash; кто СУЩЕСТВЕННО опирается на работу. TLDR &mdash; резюме в одну строку.</p>

<h3>Шаг 2.4: Документируй КАЖДЫЙ поиск</h3>
<p>В search-log.txt для каждого запроса:</p>
<pre><code>Запрос 1:
- Дата: 2026-02-27
- База: Google Scholar
- Запрос: "LLM critical thinking undergraduate"
- Фильтры: 2020-2026
- Найдено: 1,240
- Просмотрено: первые 50 (5 страниц)
- Сохранено в Zotero: 12
- Отсеяно: 38 (20 нерелевантных, 10 opinion pieces, 5 не-англ., 3 дубликата)</code></pre>

<div class="tip"><b>Это не бюрократия &mdash; это защита от cherry-picking.</b> Когда рецензент спросит "как вы искали литературу?" &mdash; покажешь search-log и он увидит системный подход.</div>

<h3>Шаг 2.5: Когда остановиться</h3>
<p><b>Цель:</b> 30-80 источников в Zotero.</p>
<p><b>Хватит, когда:</b> новые запросы находят статьи которые уже видел (saturation); Connected Papers даёт те же кружки; основные авторы повторяются.</p>
<p><b>Мало, когда:</b> есть тема из одной статьи без углубления; искал по 3 из 15 терминов; Connected Papers показывает нетронутый кластер.</p>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 2</summary>
<div class="content">
<p>Эта фаза выполняется в <b>браузере</b> (Google Scholar, Connected Papers, Semantic Scholar). Агент помогает по ходу. Начни с:</p>
<pre><code>Начинаем фазу 2: глубокий поиск литературы.

Мои текущие поисковые термины: [список из search-log]

Помоги уточнить запросы и оценить релевантность
найденных статей по абстрактам.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 3 ═══════════════════ -->

<details class="section" id="phase3">
<summary>Фаза 3: Сбор источников</summary>
<div class="phase">
<p><span class="tool-badge">Zotero</span> <span class="tool-badge">Unpaywall</span></p>

<h3>Шаг 3.1: Организуй Zotero</h3>
<p>Создай папки (Collections):</p>
<ul>
<li><code>01-Core</code> &mdash; ключевые статьи (прочитаешь сам целиком)</li>
<li><code>02-Supporting</code> &mdash; подтверждающие, менее центральные</li>
<li><code>03-Background</code> &mdash; общий фон, учебники, обзоры</li>
<li><code>04-Contradicting</code> &mdash; статьи с противоположной позицией (НЕ пропускай!)</li>
<li><code>05-Methods</code> &mdash; статьи про методологию</li>
</ul>
<p>Теги:</p>
<ul>
<li><code>has-pdf</code> &mdash; полный текст получен</li>
<li><code>abstract-only</code> &mdash; только абстракт</li>
<li><code>must-read</code> &mdash; прочитать самому обязательно</li>
<li><code>meta-analysis</code> &mdash; мета-анализы и systematic reviews</li>
</ul>

<h3>Шаг 3.2: Добывай полные тексты</h3>
<p>Для каждой статьи без PDF, по порядку:</p>
<ol>
<li><b>Unpaywall</b> &mdash; зелёный замочек на странице статьи</li>
<li><b>arXiv</b> (arxiv.org) &mdash; предпринты по CS, физике, мат., экономике. Бесплатно.</li>
<li><b>PubMed Central</b> (ncbi.nlm.nih.gov/pmc/) &mdash; биомедицина. Бесплатно.</li>
<li><b>SSRN</b> (ssrn.com) &mdash; социальные науки, экономика, право.</li>
<li><b>ResearchGate</b> &mdash; авторы выкладывают свои статьи. "Request full-text" &mdash; многие отвечают.</li>
<li><b>Библиотека вуза</b> &mdash; если аффилирован, доступ к Springer, Elsevier, Wiley через прокси.</li>
<li><b>Google Scholar &rarr; "All versions"</b> &mdash; иногда находит PDF на сайте автора.</li>
<li><b>Sci-Hub</b> &mdash; существует, работает, юридически серая зона. Решение за тобой.</li>
</ol>

<div class="warn"><b>Реальность:</b> ты НЕ получишь полные тексты всех статей. Для 40-60% &mdash; PDF. Для остальных &mdash; abstract + metadata. Это нормально, но влияет на уровень уверенности (фаза 8).</div>

<h3>Шаг 3.3: Подготовь для NotebookLM</h3>
<ol>
<li>Собери все PDF в одну папку <code>papers-pdf/</code></li>
<li>Проверь что файлы читаемы (сканы низкого качества NotebookLM не переварит)</li>
</ol>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 3</summary>
<div class="content">
<p>Эта фаза выполняется в <b>Zotero</b> и браузере. Агент помогает с организацией:</p>
<pre><code>Начинаем фазу 3: сбор источников.

У меня [N] статей в Zotero. Помоги организовать коллекции
и теги, подскажи где искать полные тексты.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 4 ═══════════════════ -->

<details class="section" id="phase4">
<summary>Фаза 4: Построение базы знаний (NotebookLM)</summary>
<div class="phase">
<p><span class="tool-badge">NotebookLM</span></p>

<h3>Шаг 4.1: Создай notebook</h3>
<ol>
<li>notebooklm.google.com &rarr; "New Notebook"</li>
<li>"Upload Sources" &rarr; загрузи PDF из <code>papers-pdf/</code></li>
<li>До 50 источников в один notebook. Если больше &mdash; создай два по подтемам.</li>
</ol>

<h3>Шаг 4.2: Первичное исследование</h3>
<p>Начни с широких вопросов:</p>
<pre><code>Какие основные темы и направления исследований
прослеживаются в загруженных источниках?</code></pre>
<pre><code>Какие методологические подходы используются чаще всего?
Перечисли с указанием конкретных авторов и статей.</code></pre>
<pre><code>Какие ключевые определения [термина] дают разные авторы?
Есть ли расхождения?</code></pre>
<pre><code>Какие эмпирические результаты получены по [аспекту]?
Приведи данные из конкретных исследований.</code></pre>

<div class="tip"><b>Ключевое:</b> NotebookLM отвечает С НОМЕРАМИ ИСТОЧНИКОВ [1], [3], [7]. Нажми на номер &mdash; увидишь точную цитату из конкретного PDF. ЭТО ВЕРИФИКАЦИЯ. Claude этого не умеет.</div>

<h3>Шаг 4.3: Найди противоречия</h3>
<pre><code>Есть ли в моих источниках противоречивые результаты?
Покажи конкретные пары статей с разными выводами по одному вопросу.</code></pre>
<pre><code>По вопросу [аспект] — кто соглашается, кто расходится?
Покажи позиции с цитатами.</code></pre>

<h3>Шаг 4.4: Найди пробелы (gaps)</h3>
<pre><code>Какие вопросы поднимаются как "future work" или "limitations"?
Какие до сих пор не решены?</code></pre>
<pre><code>Какие аспекты [темы] НЕ покрыты в загруженных источниках?</code></pre>

<h3>Шаг 4.5: Audio Overview</h3>
<p>Нажми "Audio Overview" в NotebookLM. Подкаст 10-20 минут. Помогает увидеть общую картину, особенно если потерялся в деталях.</p>

<h3>Шаг 4.6: ЧИТАЙ САМ</h3>
<div class="warn"><b>Это не опционально.</b> Выбери 5-10 ключевых статей (папка 01-Core в Zotero) и прочитай целиком. Не абстракт, не пересказ NotebookLM &mdash; сам текст.</div>
<p><b>Почему:</b></p>
<ul>
<li>Не поймёшь нюансы методологии из пересказа</li>
<li>Не увидишь оговорки и limitations которые AI пропускает</li>
<li>Не напишешь хорошую дискуссию без понимания предмета</li>
<li>Рецензент увидит если не читал ключевые работы</li>
</ul>
<p>При чтении записывай: claims, evidence, limitations, future work, свои мысли.</p>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 4</summary>
<div class="content">
<p>Эта фаза выполняется в <b>NotebookLM</b> (браузер). После работы с NotebookLM отправь результаты агенту:</p>
<pre><code>Фаза 4: база знаний построена. Вот мои заметки из NotebookLM:

[вставь ключевые findings, цитаты, противоречия]

Помоги структурировать по темам и предложи
дополнительные вопросы для NotebookLM.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 5 ═══════════════════ -->

<details class="section" id="phase5">
<summary>Фаза 5: Синтез (Claude + NotebookLM)</summary>
<div class="phase">
<p><span class="tool-badge">Claude</span> <span class="tool-badge">NotebookLM</span></p>

<h3>Шаг 5.1: Перенеси insights агенту</h3>
<p>Скопируй ключевые заметки из NotebookLM и свои заметки из чтения, отправь агенту:</p>
<pre><code>Я работаю над статьёй. Вопрос: [вопрос]

Мои заметки из литературы (источники реальные, проверены):

ТЕМА 1: [название]
- [Автор1, год]: утверждает что...
- [Автор2, год]: утверждает что...
- Противоречие: Автор1 говорит X, Автор2 говорит Y

ТЕМА 2: [название]
- ...

ПРОБЕЛЫ (не покрыто):
- ...

Помоги:
1. Сгруппировать в тематические блоки
2. Для каждого: консенсус, противоречия, пробелы
3. Предложить структуру аргументации для статьи</code></pre>

<h3>Шаг 5.2: Построй argument map</h3>
<pre><code>На основе группировки, построй argument map:

ТЕЗИС: [основной тезис]

ЗА (supporting evidence):
- [какие исследования, что показали]

ПРОТИВ (counter-evidence):
- [какие противоречат]

НЕ РЕШЕНО (gaps):
- [что неизвестно]

МЕТОДОЛОГИЯ:
- [какие подходы доминируют, какие недопредставлены]

Для каждого пункта &mdash; конкретные авторы и годы из моих заметок.</code></pre>

<h3>Шаг 5.3: Проверь агента через NotebookLM</h3>
<p>Агент может переврать заметки или добавить лишнее. Для каждого ключевого утверждения:</p>
<pre><code>[В NotebookLM:]
Правда ли что Smith (2024) утверждает [то что Claude написал]?
Покажи точную цитату.</code></pre>
<p>Если NotebookLM не подтверждает &mdash; claim выдуман или переврён. Убери.</p>

<h3>Шаг 5.4: Создай outline</h3>
<pre><code>Вот argument map: [вставь]

Предложи outline статьи:
- Для каждой секции &mdash; какие аргументы и источники
- Структура: Introduction, Literature Review,
  Methodology (если эмпирика), Results, Discussion, Conclusion
- Примерный объём каждой секции в словах</code></pre>

<p>Запиши в <code>outline.txt</code>.</p>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 5</summary>
<div class="content">
<p>Это основная фаза работы агента. Отправь:</p>
<pre><code>Начинаем фазу 5: синтез.

Мои заметки из литературы (источники проверены через NotebookLM):

[вставь структурированные заметки по темам]

Построй argument map и предложи outline статьи.
Используй ТОЛЬКО мои источники, ничего от себя.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 6 ═══════════════════ -->

<details class="section" id="phase6">
<summary>Фаза 6: Написание (Claude)</summary>
<div class="phase">
<p><span class="tool-badge">Claude</span></p>

<h3>Шаг 6.1: Секция за секцией</h3>
<div class="warn"><b>НИКОГДА</b> не проси Claude написать всю статью разом. Контекст кончится, качество упадёт, потеряешь контроль.</div>
<p>Для каждой секции:</p>
<pre><code>Пишу секцию "[название]" для научной статьи.

Вопрос: [вопрос]

Outline этой секции:
[из outline.txt]

Источники (из моего литобзора):
- Smith (2024): [finding]
- Jones (2023): [finding]
- Lee et al. (2022): [finding]

Раскрыть:
- [пункт 1 из argument map]
- [пункт 2]

Требования:
- Академический тон (третье лицо, осторожные формулировки)
- Каждое утверждение ссылается на источник (Author, Year)
- Hedging: "suggests that", "appears to", "may indicate"
- Объём: ~[X] слов
- НЕ придумывай источников которых нет в списке</code></pre>

<h3>Шаг 6.2: Управляй контекстом</h3>
<p>У агента есть доступ к файлам проекта, но контекст ограничен. Если сессия длинная:</p>
<ul>
<li>Агент сам прочитает outline.txt и argument-map.txt</li>
<li>Давай заметки ТОЛЬКО по текущей секции (не все 50 источников)</li>
<li>Длинная сессия &mdash; начни новую для следующей секции</li>
</ul>

<h3>Шаг 6.3: Чего НЕ делать</h3>
<ul>
<li>Не проси "найди источники" &mdash; агент выдумает</li>
<li>Не проси "добавь ещё ссылок" &mdash; сгенерирует несуществующие</li>
<li>Не принимай цитаты без проверки в NotebookLM/Zotero</li>
<li>Не копируй текст дословно &mdash; пропусти через себя, сделай своим</li>
</ul>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 6</summary>
<div class="content">
<p>Пиши секцию за секцией, не всю статью разом. Для каждой секции:</p>
<pre><code>Пишем секцию "[название]".

Outline секции: [из outline.txt]

Источники для этой секции:
- [Автор1, год]: [finding]
- [Автор2, год]: [finding]

Требования: академический тон, hedging language,
каждое утверждение со ссылкой. НЕ добавляй источников
которых нет в списке.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 7 ═══════════════════ -->

<details class="section" id="phase7">
<summary>Фаза 7: Критический разбор (Claude как рецензент)</summary>
<div class="phase">
<p><span class="tool-badge">Claude (отдельная сессия)</span></p>

<h3>Шаг 7.1: Настрой агента-критика</h3>
<p>Открой НОВУЮ сессию в приложении (важно: не в той же где писал). Задай роль:</p>
<pre><code>Ты — строгий академический рецензент (Reviewer 2).
Найди все слабые места в тексте.

Проверяй:

ЛОГИКА:
- Circular reasoning (аргумент доказывает сам себя)?
- Non sequitur (вывод не следует из посылок)?
- Подмена тезиса?
- Correlation != causation?

ФАЛЬСИФИЦИРУЕМОСТЬ:
- Можно ли опровергнуть каждый тезис?
- Нефальсифицируемый тезис = бессмысленный.

CHERRY-PICKING:
- Автор игнорирует противоположные данные?
- Представлены ли counter-arguments?

ИСТОЧНИКИ:
- Утверждения без ссылок?
- Чрезмерная зависимость от одного источника?
- Достаточно ли свежие?

СТИЛЬ:
- Академический тон?
- Нет маркетинговых фраз ("revolutionary", "groundbreaking")?
- Hedging где нужно?

СТРУКТУРА:
- Логика от Introduction к Conclusion?
- "Прыжки" между темами?
- Повторы?

Будь жёстким. Лучше исправлю сейчас, чем рецензент вернёт.</code></pre>

<h3>Шаг 7.2: Отправляй по секциям</h3>
<pre><code>Секция Literature Review:

[текст]

Разбери по всем критериям. Для каждого замечания:
цитата + проблема + как исправить.</code></pre>

<h3>Шаг 7.3: Веди review-log</h3>
<pre><code>REVIEW LOG
==========

Секция: Literature Review
Дата: [дата]

Замечание 1 (ЛОГИКА):
- Цитата: "The data clearly demonstrates that..."
- Проблема: overstatement, данные показывают корреляцию
- Решение: заменить на "The data suggests a positive association..."
- Статус: ИСПРАВЛЕНО / В РАБОТЕ

Замечание 2 (CHERRY-PICKING):
- Цитата: [абзац]
- Проблема: не упомянуты данные Jones (2023) которые противоречат
- Решение: добавить абзац с counter-evidence
- Статус: ИСПРАВЛЕНО / В РАБОТЕ</code></pre>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 7</summary>
<div class="content">
<p><b>Важно:</b> открой новую сессию в приложении. Критик и писатель &mdash; разные сессии. Отправь:</p>
<pre><code>Ты — Reviewer 2, строгий академический рецензент.
Разбери текст по критериям: логика, фальсифицируемость,
cherry-picking, источники, стиль, структура.

Для каждого замечания: цитата + проблема + как исправить.
Будь жёстким.

Секция: [название]

[текст секции]</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 8 ═══════════════════ -->

<details class="section" id="phase8">
<summary>Фаза 8: Верификация (NotebookLM + scite.ai)</summary>
<div class="phase">
<p><span class="tool-badge">NotebookLM</span> <span class="tool-badge">scite.ai</span></p>

<h3>Шаг 8.1: Claim-by-claim проверка</h3>
<p>Для каждого утверждения в тексте со ссылкой на источник:</p>
<pre><code>[В NotebookLM:]
Статья Smith (2024) утверждает что [claim из текста]?
Покажи точную цитату.</code></pre>

<p>Записывай в <code>verification-log.txt</code>:</p>
<div class="table-wrap"><table>
<tr><th>Claim в тексте</th><th>Источник</th><th>Подтверждено?</th><th>Цитата</th><th>Статус</th></tr>
<tr><td>LLM снижают critical thinking на 15%</td><td>Smith 2024</td><td>ДА</td><td>"We observed a 15.2% decrease..." p.7</td><td>CONFIRMED</td></tr>
<tr><td>Студенты предпочитают AI-фидбек</td><td>Jones 2023</td><td>ЧАСТИЧНО</td><td>"mixed results"</td><td>NEEDS HEDGING</td></tr>
<tr><td>AI увеличивает продуктивность в 3 раза</td><td>Lee 2022</td><td>НЕТ</td><td>Нет такого утверждения</td><td>REMOVE</td></tr>
</table></div>

<p><b>Статусы:</b></p>
<ul>
<li><b>CONFIRMED</b> &mdash; ок</li>
<li><b>NEEDS HEDGING</b> &mdash; источник мягче, переформулируй осторожнее</li>
<li><b>REMOVE</b> &mdash; не подтверждён, убери или найди другой источник</li>
<li><b>ABSTRACT ONLY</b> &mdash; полный текст недоступен. Формулируй осторожнее: "Smith (2024) reports..." а не "demonstrated"</li>
</ul>

<h3>Шаг 8.2: scite.ai &mdash; качество источников</h3>
<p>Для 10-15 ключевых источников:</p>
<ol>
<li>Найди статью на scite.ai (по DOI или названию)</li>
<li>Посмотри Smart Citations: Supporting / Contrasting / Mentioning</li>
</ol>
<p><b>Red flags:</b></p>
<ul>
<li>Много contrasting &rarr; источник спорный, упомяни дебаты</li>
<li>Мало цитирований вообще &rarr; статья не повлияла на поле</li>
<li>Retraction notice &rarr; УБРАТЬ НЕМЕДЛЕННО</li>
</ul>

<h3>Шаг 8.3: Метрики качества</h3>
<p>Посчитай и запиши в <code>quality-metrics.txt</code>:</p>
<div class="table-wrap"><table>
<tr><th>Метрика</th><th>Формула</th><th>Цель</th><th>Факт</th><th>Статус</th></tr>
<tr><td>Coverage</td><td>Темы с 3+ источниками / всего тем</td><td>&gt;80%</td><td></td><td></td></tr>
<tr><td>Full-text access</td><td>Источники с PDF / всего</td><td>&gt;40%</td><td></td><td></td></tr>
<tr><td>Contradictions resolved</td><td>Разрешённые / всего</td><td>100%</td><td></td><td></td></tr>
<tr><td>Claim traceability</td><td>Claims с источником / всего</td><td>100%</td><td></td><td></td></tr>
<tr><td>Recency</td><td>Источники &lt;5 лет / всего</td><td>&gt;50%</td><td></td><td></td></tr>
<tr><td>Source diversity</td><td>Уникальных журналов / всего</td><td>&gt;30%</td><td></td><td></td></tr>
<tr><td>Falsifiability</td><td>Claims с критерием опровержимости / всего</td><td>&gt;70%</td><td></td><td></td></tr>
</table></div>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 8</summary>
<div class="content">
<p>Верификация идёт в <b>NotebookLM</b> и <b>scite.ai</b>. Агент помогает организовать процесс:</p>
<pre><code>Начинаем фазу 8: верификация.

Составь список всех claims в тексте которые ссылаются
на источники. Для каждого я проверю в NotebookLM
и запишу результат. Помоги посчитать метрики качества.</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ PHASE 9 ═══════════════════ -->

<details class="section" id="phase9">
<summary>Фаза 9: Финализация</summary>
<div class="phase">
<p><span class="tool-badge">Zotero</span> <span class="tool-badge">Claude</span></p>

<h3>Шаг 9.1: Библиография</h3>
<ol>
<li>В Zotero: убедись что все использованные источники на месте</li>
<li>Удали из коллекции не вошедшие в финальный текст</li>
<li>Правый клик на коллекцию &rarr; "Create Bibliography"</li>
<li>Выбери формат журнала (APA 7th, Harvard, Chicago, IEEE...)</li>
<li>Проверь: каждая ссылка в тексте есть в библиографии и наоборот</li>
</ol>

<h3>Шаг 9.2: Плагиат и AI-detection</h3>
<ul>
<li><b>Turnitin</b> (через вуз) &mdash; золотой стандарт</li>
<li><b>Grammarly Premium</b> &mdash; plagiarism + AI detection</li>
<li><b>GPTZero</b> (gptzero.me) &mdash; AI detection бесплатно до лимита</li>
</ul>
<div class="warn"><b>Важно:</b> узнай политику своего университета / журнала по AI ДО начала работы. Некоторые разрешают с disclosure, некоторые запрещают.</div>

<h3>Шаг 9.3: Финальная стилистическая правка</h3>
<pre><code>Ты — academic editor. Отредактируй:
- Убери разговорные обороты
- Проверь согласованность терминов
- Проверь transitions между абзацами и секциями
- Abstract точно отражает содержание?
- Conclusion не вводит новых аргументов?

[текст]</code></pre>

<h3>Шаг 9.4: Прочитай вслух</h3>
<p>Прочитай весь текст вслух от начала до конца. Ухо ловит то, что глаз пропускает: длинные запутанные предложения, повторы, нелогичные переходы.</p>

<details class="agent-instructions">
<summary>Промт для запуска Фазы 9</summary>
<div class="content">
<p>Финальная редактура. Отправь агенту секцию за секцией:</p>
<pre><code>Фаза 9: финальная редактура.

Ты — academic editor. Отредактируй стилистику:
убери разговорные обороты, проверь единообразие терминов,
transitions между абзацами. НЕ меняй содержание и источники.

Секция: [название]

[текст]</code></pre>
</div>
</details>

</div>
</details>

<!-- ═══════════════════ FILES ═══════════════════ -->

<details class="section" id="files">
<summary>Файловая структура проекта</summary>
<div class="phase">
<p>Агент создаст эту структуру автоматически при запуске. Общая папка для всех проектов:</p>
<pre><code>research-papers/              -- корневая папка (английское имя!)
  memory/                     -- твой опыт, сохраняется между проектами
  templates/                  -- обкатанные шаблоны
  my-first-paper/             -- проект статьи
    CLAUDE.md                 -- инструкции для агента (не трогай)
    tasker.yaml               -- текущие задачи и прогресс
    search-log.txt            -- стратегия поиска, лог запросов
    outline.txt               -- структура статьи
    argument-map.txt          -- тезис: за, против, неизвестно
    review-log.txt            -- замечания критика
    verification-log.txt      -- claim: источник: вердикт
    quality-metrics.txt       -- метрики покрытия и достоверности
    papers-pdf/               -- PDF источников (для NotebookLM)
    phases/                   -- протоколы по фазам (не трогай)
    draft/
      01-introduction.txt
      02-literature.txt
      03-methodology.txt      -- если эмпирика
      04-results.txt          -- если эмпирика
      05-discussion.txt
      06-conclusion.txt
  my-second-paper/            -- следующая статья
    ...</code></pre>
<p><b>memory/</b> и <b>templates/</b> &mdash; общие для всех проектов. Опыт первой статьи помогает при второй.</p>
</div>
</details>

<!-- ═══════════════════ PRINCIPLES ═══════════════════ -->

<details class="section" id="principles">
<summary>Принципы (перечитывай когда сомневаешься)</summary>
<div class="phase">
<ol>
<li><b>Claude выдумывает источники.</b> Каждый раз. Без исключений. НИКОГДА не бери ссылку из Claude без проверки.</li>
<li><b>NotebookLM отвечает только из твоих документов.</b> Это его сила. Если не подтверждает &mdash; claim вероятно ложный.</li>
<li><b>Ты &mdash; мост и судья.</b> AI не заменяет твоё понимание. Ты переносишь insights между инструментами и принимаешь все решения.</li>
<li><b>Документируй всё.</b> Search log, verification log, review log &mdash; доказательство системного подхода.</li>
<li><b>Чтение обязательно.</b> 5-10 ключевых статей целиком, самому.</li>
<li><b>Один инструмент &mdash; одна задача.</b> Deep Research ищет, NotebookLM хранит и верифицирует, Claude думает и пишет.</li>
<li><b>Не торопись.</b> Каждая фаза закончена до начала следующей.</li>
<li><b>Academic integrity.</b> Знай правила. Disclosure &mdash; если требуется.</li>
</ol>
</div>
</details>

<!-- ═══════════════════ CHECKLIST ═══════════════════ -->

<details class="section" id="checklist">
<summary>Финальный чеклист</summary>
<div class="phase">
<ul class="checklist">
<li>Research question чётко сформулирован в Introduction</li>
<li>Search strategy документирована в search-log</li>
<li>Все sources из текста есть в библиографии (и наоборот)</li>
<li>Каждый claim проверен через NotebookLM (verification-log)</li>
<li>Contradictions адресованы в Discussion</li>
<li>Gaps названы (Discussion или Future Work)</li>
<li>Ключевые источники проверены через scite.ai</li>
<li>Review-log: все замечания исправлены или обоснованно отклонены</li>
<li>Quality metrics посчитаны, критичные в зелёной зоне</li>
<li>Библиография в правильном формате</li>
<li>Текст прочитан вслух</li>
<li>Проверка на плагиат / AI-detection пройдена</li>
<li>AI disclosure написан если требуется</li>
<li>Abstract написан ПОСЛЕДНИМ и точно отражает содержание</li>
</ul>
</div>
</details>

<!-- ═══════════════════ GLOSSARY ═══════════════════ -->

<details class="section" id="glossary">
<summary>Глоссарий: основные термины</summary>
<div class="phase">

<div class="table-wrap"><table>
<tr><th style="width:30%">Термин</th><th>Что значит</th></tr>
<tr><td><b>Research question</b></td><td>Исследовательский вопрос &mdash; конкретный вопрос, на который отвечает твоя статья. Не тема, а именно вопрос ("Как X влияет на Y?").</td></tr>
<tr><td><b>Research gap</b></td><td>Пробел в знаниях &mdash; что-то, что наука ещё не исследовала или исследовала недостаточно. Обоснование того, зачем твоя статья нужна.</td></tr>
<tr><td><b>Peer review</b></td><td>Экспертная рецензия. Статью проверяют 2-3 анонимных учёных перед публикацией. Если журнал peer-reviewed &mdash; это знак качества.</td></tr>
<tr><td><b>Abstract</b></td><td>Краткое резюме статьи (150-300 слов): вопрос, метод, результат, вывод. Пишется ПОСЛЕДНИМ, читается ПЕРВЫМ.</td></tr>
<tr><td><b>Literature review</b></td><td>Обзор литературы &mdash; секция статьи где ты показываешь, что уже известно по теме, и где пробелы.</td></tr>
<tr><td><b>Systematic review</b></td><td>Систематический обзор &mdash; обзор литературы по строгому протоколу: задокументированы запросы, критерии включения/исключения, всё воспроизводимо.</td></tr>
<tr><td><b>Meta-analysis</b></td><td>Мета-анализ &mdash; статистическое объединение результатов нескольких исследований. Самый сильный тип доказательства.</td></tr>
<tr><td><b>DOI</b></td><td>Digital Object Identifier &mdash; уникальный код статьи (пример: 10.1038/s41586-024-07421-0). По нему находишь статью однозначно.</td></tr>
<tr><td><b>Impact factor</b></td><td>Рейтинг журнала. Средне число цитирований на статью. Nature ~65, хороший специализированный журнал ~3-10, слабый &lt;1.</td></tr>
<tr><td><b>Predatory journal</b></td><td>"Хищнический" журнал &mdash; публикует за деньги без реальной рецензии. Публикация там = антирепутация.</td></tr>
<tr><td><b>Open access</b></td><td>Статья в свободном доступе (не за пейволлом). Бывает gold (журнал бесплатный), green (автор выложил копию).</td></tr>
<tr><td><b>Preprint</b></td><td>Предпринт &mdash; статья выложена ДО рецензии (arXiv, SSRN). Быстрый доступ, но не проверена экспертами.</td></tr>
<tr><td><b>Citation / Ссылка</b></td><td>Указание на источник. В тексте: (Smith, 2024). В библиографии: полные данные. Каждое утверждение = ссылка.</td></tr>
<tr><td><b>Hedging language</b></td><td>Осторожные формулировки: "suggests", "may indicate", "appears to". В науке не "доказано", а "данные указывают на". Категоричность = слабость.</td></tr>
<tr><td><b>Falsifiability</b></td><td>Фальсифицируемость &mdash; возможность опровергнуть утверждение. "AI полезен" &mdash; нефальсифицируемо (бессмысленно). "AI снижает ошибки на 15%" &mdash; фальсифицируемо (можно проверить).</td></tr>
<tr><td><b>Cherry-picking</b></td><td>Выборочное цитирование &mdash; когда берёшь только подтверждающие источники и игнорируешь опровергающие. Главный грех литобзора.</td></tr>
<tr><td><b>Circular reasoning</b></td><td>Порочный круг &mdash; аргумент доказывает сам себя. "AI эффективен, потому что он улучшает результаты" (тавтология).</td></tr>
<tr><td><b>Correlation vs Causation</b></td><td>Корреляция &ne; причинность. "Страны с высоким потреблением шоколада имеют больше нобелевских лауреатов" &mdash; корреляция, не причина.</td></tr>
<tr><td><b>Hallucination (AI)</b></td><td>Галлюцинация &mdash; когда AI уверенно выдаёт выдуманную информацию. Claude регулярно придумывает несуществующие статьи с правдоподобными названиями и авторами.</td></tr>
<tr><td><b>Inclusion / Exclusion criteria</b></td><td>Критерии включения/исключения &mdash; правила отбора статей: какие берём (годы, язык, тип), какие нет и почему. Документируются ДО поиска.</td></tr>
<tr><td><b>Saturation</b></td><td>Насыщение &mdash; момент когда новые запросы находят уже знакомые статьи. Признак что поиск достаточно полный.</td></tr>
<tr><td><b>Retraction</b></td><td>Отзыв статьи &mdash; журнал признал что статья содержит ошибки, фальсификацию или плагиат. Ссылаться на retracted статью = провал.</td></tr>
<tr><td colspan="2" style="background:var(--card);text-align:center;font-weight:bold;color:var(--accent)">AI и инструменты</td></tr>
<tr><td><b>LLM</b></td><td>Large Language Model &mdash; большая языковая модель. Claude, GPT, Gemini &mdash; всё это LLM. Обучены на текстах, генерируют текст. Не "думают" &mdash; предсказывают следующее слово (очень хорошо).</td></tr>
<tr><td><b>Prompt / Промт</b></td><td>Текст, который ты отправляешь AI. Качество ответа напрямую зависит от качества промта. "Напиши статью" &mdash; плохой промт. "Напиши Introduction по outline, используя только эти 5 источников" &mdash; хороший.</td></tr>
<tr><td><b>Context window</b></td><td>Контекстное окно &mdash; объём текста, который AI "помнит" в рамках одного разговора. Ограничен. Когда кончается &mdash; AI начинает забывать начало разговора. Поэтому пишем секцию за секцией, а не всю статью разом.</td></tr>
<tr><td><b>Token / Токен</b></td><td>Единица текста для AI. Примерно 1 токен = 0.75 слова (для английского). Контекстное окно измеряется в токенах. Claude Pro &mdash; ~200K токенов (~150K слов), но качество падает задолго до лимита.</td></tr>
<tr><td><b>Session / Сессия</b></td><td>Один разговор с AI от начала до конца. Новая сессия = чистый лист, AI не помнит предыдущую. Поэтому в фазе 7 критик работает в ОТДЕЛЬНОЙ сессии &mdash; чтобы не защищал свой же текст.</td></tr>
<tr><td><b>System prompt</b></td><td>Скрытая инструкция, которая задаёт поведение AI до начала разговора. CLAUDE.md в этом гайде &mdash; по сути system prompt. Пользователь его не пишет, но он определяет как агент работает.</td></tr>
<tr><td><b>Grounding</b></td><td>"Заземление" &mdash; привязка ответов AI к конкретным данным вместо генерации из головы. NotebookLM grounded в твоих PDF &mdash; поэтому не выдумывает. Claude по умолчанию НЕ grounded &mdash; поэтому выдумывает.</td></tr>
<tr><td><b>RAG</b></td><td>Retrieval-Augmented Generation &mdash; AI сначала ищет в базе документов, потом генерирует ответ на основе найденного. NotebookLM работает по принципу RAG. Это то, что делает его надёжным для верификации.</td></tr>
<tr><td><b>Temperature</b></td><td>Параметр "креативности" AI. Низкая (0) &mdash; предсказуемый, точный. Высокая (1) &mdash; разнообразный, но менее надёжный. Для научных текстов хочешь низкую. В Claude настраивать не нужно &mdash; он сам выбирает.</td></tr>
<tr><td><b>Zero-shot / Few-shot</b></td><td>Zero-shot &mdash; AI решает задачу без примеров ("напиши абстракт"). Few-shot &mdash; с примерами ("вот 3 хороших абстракта, напиши похожий"). Few-shot обычно даёт лучший результат для форматирования.</td></tr>
<tr><td><b>Chain of thought</b></td><td>Цепочка рассуждений &mdash; когда AI "думает вслух" шаг за шагом. Повышает качество сложных задач. Если агент молча выдаёт результат &mdash; попроси "покажи рассуждение". Ошибки станут видны.</td></tr>
<tr><td><b>Fine-tuning</b></td><td>Дообучение модели на специфических данных. Claude и GPT fine-tuned для разных задач &mdash; поэтому ведут себя по-разному. Тебе это делать не нужно, но полезно понимать почему модели отличаются.</td></tr>
<tr><td><b>Agentic workflow</b></td><td>Агентный подход &mdash; AI не просто отвечает на вопросы, а выполняет задачи: читает файлы, создаёт документы, проверяет результат. Этот гайд построен на агентном подходе &mdash; Claude работает с файлами твоего проекта.</td></tr>
</table></div>
</div>
</details>

</div>
<!-- Hidden data for templates.md download (not visible in browser) -->
<script type="text/template" id="tmpl-phases">
# Phase 0: Research Question Formulation

## Context
Help user go from vague topic to concrete, falsifiable research question.

## Tasks
- [P1] Help user articulate their topic in their own words
  done_when: user has described their topic freely
- [P1] Generate 3-5 research question variants (broad to narrow)
  done_when: variants written, each checked against 4 criteria
- [P1] Validate chosen question: specificity, researchability, falsifiability, novelty
  done_when: all 4 criteria explicitly checked and passed
- [P2] Generate 15+ English search queries for Google Scholar
  done_when: queries written to search-log.txt
- [P2] Generate terms for Semantic Scholar, synonyms, related concepts
  done_when: added to search-log.txt
- [P2] Define inclusion/exclusion criteria
  done_when: criteria recorded in search-log.txt (language, years, types)

## Constraints
- Do NOT search for literature (phases 1-2)
- Do NOT name specific authors or papers (you WILL hallucinate them)
- Do NOT claim the question is "definitely new" — you don't know
- Do NOT skip to writing — this phase is about the QUESTION only
- Do NOT dump all tasks at once. Start with task 1: ask the user to describe their topic in their own words. Wait for their answer. Then proceed one task at a time.

## Gate -> Phase 1
- [ ] Research question recorded in search-log.txt
- [ ] Question passed all 4 criteria
- [ ] 15+ search terms generated
- [ ] Inclusion/exclusion criteria defined
- [ ] User confirmed question is what they want to research

Show gate checklist to user. All items must pass before Phase 1.

---

# Phase 1: Reconnaissance (Google Deep Research)

## Context
User runs Google Deep Research in browser. Agent helps AFTER, not during.

## Tasks
- [P1] Guide user to run Deep Research with proper prompt
  done_when: user has run Deep Research and received report
- [P1] Help interpret Deep Research results
  done_when: key authors, theories, meta-analyses identified
- [P2] Extract new search terms from report
  done_when: new terms added to search-log.txt
- [P2] Identify target journals
  done_when: journal list added to search-log.txt

## Constraints
- Do NOT search for literature yourself
- Do NOT add "your own" sources — you have none
- Do NOT confirm Deep Research findings as correct — they may contain errors

## Gate -> Phase 2
- [ ] Deep Research report processed
- [ ] Key authors listed in search-log.txt
- [ ] Key theories/frameworks identified
- [ ] Meta-analyses and systematic reviews noted (if any)
- [ ] Search terms expanded with new terminology

---

# Phase 2: Deep Literature Search

## Context
User searches in browser (Scholar, Connected Papers, Semantic Scholar). Agent assists.

## Tasks
- [P1] Help refine search queries if results are irrelevant
  done_when: user reports satisfactory search results
- [P1] Help evaluate relevance from abstracts
  done_when: user has clear include/exclude decisions
- [P2] Suggest additional synonyms and terms
  done_when: added to search-log.txt
- [P2] Help document each search in search-log
  done_when: each query logged with date, database, filters, counts
- [P3] Help assess saturation
  done_when: user confirms new searches yield mostly known results

## Constraints
- Do NOT name specific papers or DOIs — you will hallucinate them
- Do NOT say "this paper is good" about a paper you haven't read
- Do NOT generate URLs — you don't know real ones

## Gate -> Phase 3
- [ ] 30-80 sources saved in Zotero
- [ ] All searches documented in search-log.txt
- [ ] Saturation reached (new queries yield known results)
- [ ] Connected Papers explored for key works

---

# Phase 3: Source Collection

## Context
User works in Zotero and browser. Agent's role is minimal.

## Tasks
- [P1] Help organize Zotero collections and tags
  done_when: collections created (Core, Supporting, Background, Contradicting, Methods)
- [P1] Guide user on finding full texts (Unpaywall, arXiv, PMC, SSRN)
  done_when: user has attempted all channels for missing PDFs
- [P2] Help prepare PDFs for NotebookLM
  done_when: papers-pdf/ folder populated with readable PDFs

## Constraints
- Do NOT generate links to PDFs (you don't know real URLs)
- Do NOT assess paper quality (you haven't read them)

## Gate -> Phase 4
- [ ] Zotero organized with collections and tags
- [ ] Full texts obtained for 40%+ of sources
- [ ] papers-pdf/ folder ready for NotebookLM
- [ ] Core sources identified (5-10 must-reads)

---

# Phase 4: Knowledge Base (NotebookLM)

## Context
User works in NotebookLM (browser). Agent helps structure results AFTER.
This is where YAML becomes useful — structured source cards.

## Tasks
- [P1] Guide user through NotebookLM setup and initial questions
  done_when: notebook created, PDFs uploaded, first questions asked
- [P1] Help structure findings from NotebookLM into source cards (YAML)
  done_when: source-cards.yaml created with cards for key sources
- [P2] Help identify contradictions between sources
  done_when: contradictions documented
- [P2] Help identify gaps in coverage
  done_when: gaps documented
- [P3] Suggest Audio Overview for big-picture understanding
  done_when: user has listened or decided to skip

## Constraints
- Do NOT answer questions about paper contents — you haven't read them, NotebookLM has
- Do NOT supplement findings with "your knowledge" — this is contamination
- Do NOT replace NotebookLM — direct user there for factual questions

## Gate -> Phase 5
- [ ] NotebookLM notebook populated with sources
- [ ] Source cards created for key papers
- [ ] Contradictions documented
- [ ] Gaps identified
- [ ] User has READ 5-10 core papers themselves (not just summaries)

---

# Phase 5: Synthesis (Claude + NotebookLM)

## Context
This is the agent's primary phase. Synthesize user's notes into structure.

## Tasks
- [P1] Group user's notes by themes
  done_when: thematic grouping created and saved
- [P1] Build argument map (thesis, supporting, contradicting, unknown)
  done_when: argument-map.txt created
- [P1] Propose paper outline
  done_when: outline.txt created with sections, arguments, sources per section
- [P2] Cross-check with NotebookLM (user verifies key claims)
  done_when: user confirmed argument map accuracy via NotebookLM

## Constraints
- Work ONLY with notes provided by user
- Do NOT add "your own" sources or findings
- If data is insufficient for a conclusion — say so explicitly, don't fill gaps from imagination
- Every claim in argument map must reference a specific author from user's notes

## Gate -> Phase 6
- [ ] Thematic synthesis complete
- [ ] Argument map saved (argument-map.txt)
- [ ] Outline saved (outline.txt) with sources per section
- [ ] Key claims verified by user through NotebookLM

---

# Phase 6: Writing (Claude)

## Context
Write paper section by section based on outline and notes.

## Tasks
For each section in outline.txt:
- [P1] Write section draft using provided sources only
  done_when: draft saved to draft/ directory
- [P2] Ensure every claim has a citation from user's source list
  done_when: no unsupported claims remain
- [P2] Apply hedging language (suggests, appears, may indicate)
  done_when: no categorical statements without evidence

## Constraints
- Use ONLY sources from user's list. Not a single "your own" source.
- If a paragraph needs more sources — say "need a source on [topic]", don't fabricate
- If user asks "add more references" — REFUSE. Explain you will hallucinate. Suggest NotebookLM/Scholar.
- Never use "clearly", "obviously", "proves" — not academic tone
- Write one section per session if context is limited

## Gate -> Phase 7
- [ ] All sections drafted (draft/ directory complete)
- [ ] Every claim has a citation
- [ ] Hedging language used throughout
- [ ] No invented sources

---

# Phase 7: Critical Review (Claude as Reviewer 2)

## Context
SEPARATE SESSION from the writer. Role: strict academic reviewer.

## Tasks
- [P1] Review each section for logical problems
  done_when: all issues logged in review-log.txt
- [P1] Check falsifiability of key claims
  done_when: non-falsifiable claims flagged
- [P1] Check for cherry-picking (missing counter-evidence)
  done_when: all one-sided arguments flagged
- [P2] Check academic tone and style
  done_when: style issues noted
- [P2] Check structure and transitions
  done_when: structural issues noted

## Constraints
- This is a SEPARATE session. Do not defend the text — attack it.
- Do not suggest adding sources the user doesn't have
- If a whole section is weak — say so directly
- Check: are ALL contradictions from literature addressed in text?

## Gate -> Phase 8
- [ ] All sections reviewed
- [ ] review-log.txt complete with all findings
- [ ] User has addressed each finding (fixed, acknowledged, or justified)

---

# Phase 8: Verification (NotebookLM + scite.ai)

## Context
Claim-by-claim verification through NotebookLM. Source quality via scite.ai.

## Tasks
- [P1] Extract all claims from text that reference sources
  done_when: claims list created
- [P1] Guide user through NotebookLM verification for each claim
  done_when: verification-log.txt filled (CONFIRMED/NEEDS HEDGING/REMOVE)
- [P2] Guide user through scite.ai for 10-15 key sources
  done_when: source quality noted (supporting vs contrasting citations)
- [P2] Calculate quality metrics
  done_when: quality-metrics.txt filled

## Constraints
- Do NOT confirm claims yourself — NotebookLM does this
- Do NOT say "this source is reliable" — you don't know. Let scite.ai show.
- Do NOT suggest replacements for REMOVE claims — you'll hallucinate

## Gate -> Phase 9
- [ ] All claims verified (verification-log.txt complete)
- [ ] No REMOVE claims remain in text (fixed or removed)
- [ ] Key sources checked via scite.ai
- [ ] Quality metrics calculated, critical ones in green zone

---

# Phase 9: Finalization

## Context
Final polish: bibliography, style, plagiarism check, AI disclosure.

## Tasks
- [P1] Help user verify bibliography matches text (every citation in text = in bibliography, and vice versa)
  done_when: no orphan citations in either direction
- [P1] Final style edit: remove colloquialisms, check term consistency, transitions
  done_when: all sections edited
- [P2] Remind user about plagiarism/AI-detection check
  done_when: user has checked or decided to check later
- [P2] Verify Abstract accurately reflects content (written LAST)
  done_when: abstract reviewed
- [P3] Verify Conclusion introduces no new arguments
  done_when: conclusion reviewed
- [P3] Update memory/ with lessons learned from this project
  done_when: memory updated for future projects

## Constraints
- Do NOT add content — only edit style
- Do NOT change claims or sources
- Do NOT skip the "read aloud" recommendation

## Gate -> DONE
- [ ] Bibliography complete and consistent with text
- [ ] All sections style-edited
- [ ] Abstract written last and reflects actual content
- [ ] Plagiarism/AI-detection addressed
- [ ] AI disclosure written if required
- [ ] User has read text aloud
- [ ] Memory updated for future projects
</script>
<script type="text/template" id="tmpl-taskers">
# Phase 0 tasker
phase: 0
title: "Research Question Formulation"
status: in_progress
tasks:
  - id: 1
    title: "Describe topic in own words"
    priority: P1
    done_when: "user has described their topic freely"
    status: pending
  - id: 2
    title: "Generate 3-5 research question variants"
    priority: P1
    done_when: "variants range from broad to narrow, all checked against 4 criteria"
    status: pending
  - id: 3
    title: "Validate chosen question against 4 criteria"
    priority: P1
    done_when: "specificity, researchability, falsifiability, novelty — all checked"
    status: pending
  - id: 4
    title: "Generate 15+ English search queries"
    priority: P2
    done_when: "queries written to search-log.txt"
    status: pending
  - id: 5
    title: "Define inclusion/exclusion criteria"
    priority: P2
    done_when: "criteria recorded in search-log.txt"
    status: pending

---
# Phase 1 tasker
phase: 1
title: "Reconnaissance (Google Deep Research)"
status: pending
tasks:
  - id: 1
    title: "Run Deep Research with proper prompt"
    priority: P1
    done_when: "user has received and shared Deep Research report"
    status: pending
  - id: 2
    title: "Extract key authors from report"
    priority: P1
    done_when: "author list added to search-log.txt"
    status: pending
  - id: 3
    title: "Identify theories and frameworks"
    priority: P1
    done_when: "frameworks documented"
    status: pending
  - id: 4
    title: "Note meta-analyses and systematic reviews"
    priority: P2
    done_when: "meta-analyses listed in search-log.txt (or noted as absent)"
    status: pending
  - id: 5
    title: "Extract new search terms"
    priority: P2
    done_when: "new terms added to search-log.txt"
    status: pending
  - id: 6
    title: "Identify target journals"
    priority: P2
    done_when: "journal list in search-log.txt"
    status: pending

---
# Phase 2 tasker
phase: 2
title: "Deep Literature Search"
status: pending
tasks:
  - id: 1
    title: "Search Google Scholar with refined queries"
    priority: P1
    done_when: "user reports satisfactory results, queries logged"
    status: pending
  - id: 2
    title: "Explore Connected Papers for key works"
    priority: P1
    done_when: "at least 2 graphs built, new sources saved"
    status: pending
  - id: 3
    title: "Search Semantic Scholar"
    priority: P2
    done_when: "Highly Influential Citations checked for key papers"
    status: pending
  - id: 4
    title: "Document each search in search-log"
    priority: P2
    done_when: "each query logged with date, database, filters, counts"
    status: pending
  - id: 5
    title: "Assess saturation"
    priority: P3
    done_when: "user confirms new searches yield mostly known results"
    status: pending

---
# Phase 3 tasker
phase: 3
title: "Source Collection"
status: pending
tasks:
  - id: 1
    title: "Organize Zotero collections"
    priority: P1
    done_when: "5 collections created (Core, Supporting, Background, Contradicting, Methods)"
    status: pending
  - id: 2
    title: "Apply tags to sources"
    priority: P1
    done_when: "tags applied (has-pdf, abstract-only, must-read, meta-analysis)"
    status: pending
  - id: 3
    title: "Obtain full texts via Unpaywall, arXiv, PMC, SSRN"
    priority: P1
    done_when: "all channels attempted, 40%+ sources have PDFs"
    status: pending
  - id: 4
    title: "Prepare papers-pdf/ for NotebookLM"
    priority: P2
    done_when: "readable PDFs collected in papers-pdf/"
    status: pending

---
# Phase 4 tasker
phase: 4
title: "Knowledge Base (NotebookLM)"
status: pending
tasks:
  - id: 1
    title: "Create NotebookLM notebook and upload PDFs"
    priority: P1
    done_when: "notebook created, PDFs uploaded successfully"
    status: pending
  - id: 2
    title: "Run initial broad questions in NotebookLM"
    priority: P1
    done_when: "themes, methods, definitions explored"
    status: pending
  - id: 3
    title: "Create source cards in YAML format"
    priority: P1
    done_when: "source-cards.yaml created with cards for 10+ key sources"
    status: pending
  - id: 4
    title: "Find contradictions between sources"
    priority: P2
    done_when: "contradicting pairs documented with citations"
    status: pending
  - id: 5
    title: "Find gaps in coverage"
    priority: P2
    done_when: "gaps documented, potential additional searches identified"
    status: pending
  - id: 6
    title: "Listen to Audio Overview"
    priority: P3
    done_when: "user listened or decided to skip"
    status: pending
  - id: 7
    title: "Read 5-10 core papers personally"
    priority: P1
    done_when: "user confirms they read core papers, notes recorded"
    status: pending

---
# Phase 5 tasker
phase: 5
title: "Synthesis"
status: pending
tasks:
  - id: 1
    title: "Group notes by themes"
    priority: P1
    done_when: "thematic grouping saved to file"
    status: pending
  - id: 2
    title: "Build argument map"
    priority: P1
    done_when: "argument-map.txt created with thesis, supporting, contradicting, unknown"
    status: pending
  - id: 3
    title: "Propose paper outline"
    priority: P1
    done_when: "outline.txt created with sections, arguments, sources per section"
    status: pending
  - id: 4
    title: "Cross-check key claims via NotebookLM"
    priority: P2
    done_when: "user verified argument map accuracy in NotebookLM"
    status: pending

---
# Phase 6 tasker
phase: 6
title: "Writing"
status: pending
tasks:
  - id: 1
    title: "Write Introduction draft"
    priority: P1
    done_when: "draft/01-introduction.txt saved, all claims cited"
    status: pending
  - id: 2
    title: "Write Literature Review draft"
    priority: P1
    done_when: "draft/02-literature.txt saved, all claims cited"
    status: pending
  - id: 3
    title: "Write Methodology draft (if empirical)"
    priority: P1
    done_when: "draft/03-methodology.txt saved or marked as N/A"
    status: pending
  - id: 4
    title: "Write Results draft (if empirical)"
    priority: P1
    done_when: "draft/04-results.txt saved or marked as N/A"
    status: pending
  - id: 5
    title: "Write Discussion draft"
    priority: P1
    done_when: "draft/05-discussion.txt saved, contradictions addressed"
    status: pending
  - id: 6
    title: "Write Conclusion draft"
    priority: P1
    done_when: "draft/06-conclusion.txt saved, no new arguments introduced"
    status: pending
  - id: 7
    title: "Verify hedging language throughout"
    priority: P2
    done_when: "no categorical statements without strong evidence"
    status: pending

---
# Phase 7 tasker
phase: 7
title: "Critical Review"
status: pending
tasks:
  - id: 1
    title: "Review Introduction for logical problems"
    priority: P1
    done_when: "issues logged in review-log.txt"
    status: pending
  - id: 2
    title: "Review Literature Review"
    priority: P1
    done_when: "cherry-picking and gaps flagged"
    status: pending
  - id: 3
    title: "Review Discussion"
    priority: P1
    done_when: "logical fallacies and missing counter-evidence flagged"
    status: pending
  - id: 4
    title: "Review Conclusion"
    priority: P1
    done_when: "no new arguments, no overstatements"
    status: pending
  - id: 5
    title: "Check falsifiability of key claims"
    priority: P1
    done_when: "non-falsifiable claims flagged"
    status: pending
  - id: 6
    title: "Check academic tone and style"
    priority: P2
    done_when: "style issues noted in review-log.txt"
    status: pending
  - id: 7
    title: "Address all review findings"
    priority: P1
    done_when: "user has fixed, acknowledged, or justified each finding"
    status: pending

---
# Phase 8 tasker
phase: 8
title: "Verification"
status: pending
tasks:
  - id: 1
    title: "Extract all claims from text"
    priority: P1
    done_when: "claims list created with source references"
    status: pending
  - id: 2
    title: "Verify claims in NotebookLM"
    priority: P1
    done_when: "verification-log.txt filled for all claims"
    status: pending
  - id: 3
    title: "Fix NEEDS HEDGING claims"
    priority: P1
    done_when: "softened language for all partially confirmed claims"
    status: pending
  - id: 4
    title: "Remove or replace REMOVE claims"
    priority: P1
    done_when: "no REMOVE claims remain in text"
    status: pending
  - id: 5
    title: "Check 10-15 key sources in scite.ai"
    priority: P2
    done_when: "supporting vs contrasting citation counts noted"
    status: pending
  - id: 6
    title: "Calculate quality metrics"
    priority: P2
    done_when: "quality-metrics.txt complete, critical metrics in green"
    status: pending

---
# Phase 9 tasker
phase: 9
title: "Finalization"
status: pending
tasks:
  - id: 1
    title: "Verify bibliography consistency"
    priority: P1
    done_when: "every citation in text is in bibliography and vice versa"
    status: pending
  - id: 2
    title: "Final style edit — all sections"
    priority: P1
    done_when: "colloquialisms removed, terms consistent, transitions smooth"
    status: pending
  - id: 3
    title: "Write Abstract (LAST)"
    priority: P1
    done_when: "abstract accurately reflects actual content of paper"
    status: pending
  - id: 4
    title: "Verify Conclusion has no new arguments"
    priority: P2
    done_when: "conclusion reviewed and confirmed"
    status: pending
  - id: 5
    title: "Plagiarism and AI-detection check"
    priority: P2
    done_when: "user has checked or explicitly decided to check later"
    status: pending
  - id: 6
    title: "Write AI disclosure (if required)"
    priority: P2
    done_when: "disclosure written or marked N/A"
    status: pending
  - id: 7
    title: "Read aloud"
    priority: P3
    done_when: "user confirms they read the full text aloud"
    status: pending
  - id: 8
    title: "Update memory for future projects"
    priority: P3
    done_when: "lessons learned, preferences, patterns saved to ../memory/"
    status: pending
</script>
<script src="guide.js"></script>
</body>
</html>
